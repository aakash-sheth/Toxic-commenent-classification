# Toxic commenent classification

This competition was organised on kaggle platform, the challenge of competition was to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. 

* Dataset provided-
Dataset of comments from Wikipedia’s talk page edits.

About program:
1. Code is written in Python 3.6
2. Following measure Python libraries are used in the code- 
* Data wrangling - Pandas, nltk, numpy
* Data Visualization- Matplotlib, seaborn, wordcloud
* Machine Learning- keras, scipy, scikitlearn
3. An external word embedding file was used in the program that can be found on following link-
https://www.kaggle.com/yekenot/fasttext-crawl-300d-2m

Training data for classification can be obtained from following link- 
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data
